{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model\n",
    "One of the major changes in tensorflow 2 from tensorfllow 1 is eagar execution. Inputs are processed more python-likely. Inputs are processed in the model when they are called. \n",
    "\n",
    "All we have to do is two things. The first one is to define the structure of the model. The second one is to define forward computation when they are called. These can be easily done with keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the structure of the model\n",
    "We can extend keras.Model class to define a model. Structure of structure of the Model can be specified within __init__ method like below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, input_dim,output_dim):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.kernel = self.add_weight(\"weight\", shape=[input_dim,output_dim])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Once we define a Model, we can create an instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(100,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining forward computation\n",
    "Forward computation defines how inputs are processed in the model. It is defined in the call method of the model. Inputs are forward-propagated by calling the model instance with inptus as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, input_dim,output_dim):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.weight1 = self.add_weight(\"weight\", shape=[input_dim,output_dim])\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        out = tf.matmul(inputs,self.weight1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(100,5)\n",
    "inp = tf.random.normal(shape=(32,100))\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Composing layers\n",
    "Models can have many layers, such as fully-connected layers, dropout layers, normalization layers and etcs. To stack layers within a model and we can freely use layers provided by keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComposedModel(keras.Model):\n",
    "    def __init__(self, output_dim,n_class,dropout_rate,n_layers):\n",
    "        super(ComposedModel,self).__init__()\n",
    "        layers = []\n",
    "        for i in range(n_layers-1):\n",
    "            layers.append(keras.layers.Dense(output_dim)) #fully_connected layers\n",
    "            layers.append(keras.layers.Dropout(dropout_rate)) #dropout\n",
    "            layers.append(keras.layers.LayerNormalization()) #normalization\n",
    "        layers.append(keras.layers.Dense(n_class))\n",
    "        self.nets = keras.Sequential(layers) #inputs are sequentially processed \n",
    "    \n",
    "    def call(self,inputs):\n",
    "        out = self.nets(inputs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ComposedModel(50,5,0.2,3)\n",
    "inp = tf.random.normal(shape=(32,100))\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building custom layers\n",
    "We can easily build custom layers by extending keras.layers.Layer class.\n",
    "\n",
    "Below is an example of custom fully-connected layers. We can also determine how to initialize weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected(keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim, init_std=0.02,use_bias=True):\n",
    "        super(FullyConnected, self).__init__()\n",
    "        self.nf = output_dim\n",
    "        self.nx = input_dim\n",
    "        self.initializer_range = init_std\n",
    "        self.use_bias = use_bias\n",
    "        self.weight = self.add_weight(\n",
    "            \"{}_weight\".format(self.name),\n",
    "            shape=[self.nx, self.nf],\n",
    "            initializer=keras.initializers.TruncatedNormal(stddev=init_std))\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(\n",
    "                \"{}_bias\".format(self.name),\n",
    "                shape=[1, self.nf],\n",
    "                initializer=tf.zeros_initializer())\n",
    "\n",
    "    def call(self, x):\n",
    "        x = tf.matmul(x, self.weight)\n",
    "        if self.use_bias:\n",
    "            x += self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, input_dim, hidden_dim, n_class, n_layers, init_std=0.02,use_bias=True):\n",
    "        super(CustomModel,self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.custom_layers = []\n",
    "        for i in range(n_layers):\n",
    "            if i ==0:\n",
    "                self.custom_layers.append(FullyConnected(input_dim,hidden_dim))\n",
    "            elif i < n_layers -1:\n",
    "                self.custom_layers.append(FullyConnected(hidden_dim,hidden_dim))\n",
    "            else:\n",
    "                self.custom_layers.append(FullyConnected(hidden_dim,n_class))\n",
    "    def call(self,x):\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.custom_layers[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomModel(100,50,5,3)\n",
    "inp = tf.random.normal(shape=(32,100))\n",
    "out = model(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Difference of keras.Model and keras.Layers\n",
    "Intuitively, we can use the Layer class to define inner computation blocks, and use the Model class to define the outer model.\n",
    "\n",
    "Technical difference of Model and Layers is that Model has built-in training, evaluation, and prediction loops (model.fit(), model.evaluate(), model.predict()). and it exposes saving and serialization APIs, whereas Layers doesn't.\n",
    "\n",
    "you can check https://www.tensorflow.org/guide/keras/custom_layers_and_models for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
